{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB: Introducing Pandas II\n",
    "\n",
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Lambda Functions with `.apply()`\n",
    "\n",
    "Apply a transformation to each record. Uses a `lambda` function.\n",
    "\n",
    "The `apply()` method should be used after you have established that you can't use a vectorized function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['sepal_len_sq'] = iris.sepal_length.apply(lambda x: x**2)\n",
    "iris.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformation involving multiple columns. Uses `axis=1` to access columns.  \n",
    "Compute average of `sepal_length`, `sepal_width`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris['sepal_len_wid_avg'] = iris[['sepal_length','sepal_width']].apply(lambda x: (x.sepal_length+x.sepal_width)/2, axis=1)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorized Version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time iris.sepal_length**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to `.apply()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time iris.sepal_length.apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "\n",
    "Involves one or more of:\n",
    "\n",
    "- splitting the data into groups\n",
    "- applying a function to each group\n",
    "- combining results\n",
    "\n",
    "### `.groupby()`\n",
    "\n",
    "Compute mean of each column, grouped (separately) by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.groupby(\"species\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pd.pivot_table()`\n",
    "\n",
    "Apply a function `aggfunc` to selected values grouped by columns\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.pivot_table.html)\n",
    "\n",
    "Compute mean sepal length for each species:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(iris, values=\"sepal_length\", columns=[\"species\"], aggfunc = np.mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and Unstacking\n",
    "\n",
    "Similar to pivoting, but requires -- and takes advantage of -- indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_w_idx = iris.copy() \n",
    "\n",
    "## Give the original index a name\n",
    "iris_w_idx.index.name = 'obs_id'\n",
    "\n",
    "## Create a multi-index, using `species` as part of the key.\n",
    "iris_w_idx = iris_w_idx.reset_index().set_index(['species','obs_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_w_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.unstack()`\n",
    "\n",
    "[Details](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.unstack.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_wide = iris_w_idx.sepal_length.unstack(fill_value=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_wide.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.stack()`\n",
    "\n",
    "[Details](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.stack.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_wide.T.stack().to_frame('sepal_length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining DataFrames\n",
    "\n",
    "### `pd.concat()`  \n",
    "\n",
    "Concatenate pandas objects along an axis.\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html)\n",
    "\n",
    "Create two dfs and vertically stack them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(3, 4))\n",
    "df2 = pd.DataFrame(np.random.randn(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concat columns**\n",
    "\n",
    "This assumes that the indexes represent IDs of specific things or events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df1, df2], axis=1, keys=['foo', 'bar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.foo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.merge()`\n",
    "\n",
    "SQL-style joining of tables (DataFrames) -- although Pandas has a `.join()` method, too.\n",
    "\n",
    "Important parameters include:\n",
    "\n",
    "- `how` : type of merge {'left', 'right', 'outer', 'inner', 'cross'}, default ‘inner’\n",
    "- `on`  : names to join on\n",
    "        \n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)\n",
    "\n",
    "Create two tables, `left` and `right`. Then right join them on `key`.  \n",
    "Right join means include all records from table on right.  \n",
    "The `key` is used for matching up the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##| tags: []\n",
    "left = pd.DataFrame({\"key\": [\"jamie\", \"bill\"], \"lval\": [15, 22]})\n",
    "right = pd.DataFrame({\"key\": [\"jamie\", \"bill\", \"asher\"], \"rval\": [4, 5, 8]})\n",
    "\n",
    "joined = pd.merge(left, right, on=\"key\", how=\"right\")\n",
    "\n",
    "print('---left')\n",
    "print(left)\n",
    "print('\\n---right')\n",
    "print(right)\n",
    "print('\\n---joined')\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the NaN inserted into the record with key=asher, since the left table didn't contain the key.\n",
    "\n",
    "**Matching column names**  \n",
    "In this next example, the value columns have the same name: *val*.  Notice what happens to the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##| tags: []\n",
    "left = pd.DataFrame({\"key\": [\"jamie\", \"bill\"], \"val\": [15, 22]})\n",
    "right = pd.DataFrame({\"key\": [\"jamie\", \"bill\", \"asher\"], \"val\": [4, 5, 8]})\n",
    "\n",
    "joined = pd.merge(left, right, on=\"key\", how=\"right\")\n",
    "\n",
    "print('---left')\n",
    "print(left)\n",
    "print('\\n---right')\n",
    "print(right)\n",
    "print('\\n---joined')\n",
    "print(joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.join()`\n",
    "\n",
    "An SQL-like joiner, but this one takes advantage of indexes.\n",
    "\n",
    "Give our dataframes indexes and distinctive columns names.\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left2 = left.set_index('key').rename(columns={'val':'val_1'})\n",
    "right2 = right.set_index('key').rename(columns={'val':'val_2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right2.join(left2) # Defaults to 'inner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right2.join(left2, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "* Use **join** if you have shared indexes\n",
    "* Use **merge** if you do not have shared indexes\n",
    "* Use **concat** to combine based on shared indexes or columns\n",
    "\n",
    "## Reshape with `.reshape()`\n",
    "\n",
    "Changes the object's shape\n",
    "\n",
    "We illustrate creating pandas Series, extracting array of length 6, and reshaping to 3x2 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a series \n",
    "ser = pd.Series([1, 1, 2, 3, 5, 8]) \n",
    "\n",
    "## extract values \n",
    "vals = ser.values \n",
    "\n",
    "print('orig data:', vals)\n",
    "print('orig type:', type(vals))\n",
    "print('orig shape:', vals.shape)\n",
    "\n",
    "## reshaping series\n",
    "reshaped_vals = vals.reshape((3, 2)) \n",
    "\n",
    "print('\\n reshaped vals:')\n",
    "print(reshaped_vals)\n",
    "print('\\n new type:', type(reshaped_vals))\n",
    "print('new shape:', reshaped_vals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including -1 as one of the dimensions tells numpy: infer this dimension from the data and the other dimensions.\n",
    "\n",
    "Example: enforce 3 columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.reshape(-1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enforce 3 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals.reshape(3,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE**  \n",
    "\n",
    "Notice the shape of original array: `(6,)`  \n",
    "This is a vector with one dimension, and is different from two-dimensional `(6,1)` array\n",
    "\n",
    "## Categoricals\n",
    "\n",
    "Categorical data takes discrete values where computation on the values does not make sense.  \n",
    "Zip code is a typical example.\n",
    "\n",
    "To include categoricals in models, they must be converted to numeric.  \n",
    "\n",
    "### `get_dummies()`\n",
    "Dummy code categorical data\n",
    "\n",
    "Important parameters: \n",
    "\n",
    "- `prefix`    : append prefix to column names (a good idea for later use)\n",
    "- `drop_first`: remove first level, as only `k-1` variables needed to represent `k` levels\n",
    "\n",
    "[Details](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = pd.DataFrame({'breed':['persian','persian','siamese','himalayan','burmese']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cats = pd.get_dummies(cats.breed, drop_first=True, prefix='breed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice `burmese` was dropped (first level by alphabet) since it can be inferred.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
